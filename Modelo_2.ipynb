{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo 2: Regressão Logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escolhemos esse modelo pois o mesmo trabalha bem com variáveis qualitativas, tendo em vista nossa pergunta que envolve os tipos de pokemon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carregando as bibliotecas\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import display  # Para ter melhor print.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encontrei o arquivo pokemon.csv, tudo certo para prosseguir com a prova!\n"
     ]
    }
   ],
   "source": [
    "#Carregando a base de dados\n",
    "filename = 'pokemon.csv'\n",
    "if filename in os.listdir():\n",
    "    print(f'Encontrei o arquivo {filename}, tudo certo para prosseguir com a prova!')\n",
    "else:\n",
    "    print(f'Não encontrei o arquivo {filename} aqui no diretório {os.getcwd()}, será que você não baixou o arquivo?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria o dataframe a partir da tabela excel\n",
    "dados = pd.read_csv('pokemon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retirando os vazios da coluna\n",
    "filtro_Nan4 = dados[\"weight_kg\"].isnull()\n",
    "dados.loc[filtro_Nan4,'weight_kg'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separando o Dataset em treinamento e teste\n",
    "X = dados[['attack','base_happiness','base_total','hp','pokedex_number','sp_attack','sp_defense','speed','weight_kg','generation','is_legendary']]\n",
    "Y = dados['type1']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y,test_size=0.40, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nomeia o classificador como logit\n",
    "logit = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luana Mitsudo\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Treina o modelo\n",
    "logit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Faz predição\n",
    "y_pred = logit.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2875"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Acurácia\n",
    "logit.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bug       0.10      0.17      0.13        30\n",
      "        dark       0.25      0.18      0.21        11\n",
      "      dragon       0.11      0.07      0.09        14\n",
      "    electric       0.25      0.17      0.20        12\n",
      "       fairy       0.22      0.40      0.29         5\n",
      "    fighting       0.20      0.07      0.10        15\n",
      "        fire       0.14      0.12      0.13        16\n",
      "      flying       0.00      0.00      0.00         1\n",
      "       ghost       0.00      0.00      0.00        11\n",
      "       grass       0.29      0.33      0.31        30\n",
      "      ground       0.50      0.13      0.21        15\n",
      "         ice       0.00      0.00      0.00         7\n",
      "      normal       0.30      0.40      0.34        45\n",
      "      poison       0.00      0.00      0.00        17\n",
      "     psychic       0.12      0.09      0.10        23\n",
      "        rock       0.14      0.18      0.16        17\n",
      "       steel       0.00      0.00      0.00         5\n",
      "       water       0.22      0.32      0.26        47\n",
      "\n",
      "    accuracy                           0.20       321\n",
      "   macro avg       0.16      0.15      0.14       321\n",
      "weighted avg       0.19      0.20      0.19       321\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luana Mitsudo\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Calulando métricas\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão\n",
    "\n",
    "Para começar o treinamento do modelo, dividimos nosso DataSet entre as colunas que vimos com melhor acurácia para moledarmos e a coluna alvo, na qual estamos trabalhando em cima. Ao treinarmos o modelo e feito a predição, vimos que a acurácia é de 28,75%, tendo em vista que é a primeira interação a porcentagem está aceitável, para melhorar essa acurácia iremos precisar de uma DataSet com mais dados.\n",
    "\n",
    "Na tabela que contem as métricas, temos precision (número de vezes que uma classe foi prevista corretamente), recall (número de vezes que uma classe foi prevista corretamente, pelos números de vezes que a mesma aparece no falso negativo), f1-score (média harmônica entre precisão e revocação), support (número de ocorrências de determinada classe em seu conjunto de dados), accuracy (quantidade de acertos sobre o todo), macro average (calcula f1 para cada rótulo e retorna a média sem considerar a proporção de cada rótulo) e weighted average (calcular f1 para cada rótulo e retorna a média considerando a proporção de cada rótulo)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
